{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hphuc-bme138/Skin-disease-dectection-using-ResNet-152-and-web-app-with-Flask-ngrok/blob/main/Skin_Disease_Detection_using_ResNet_152_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install the environment and required libraries**"
      ],
      "metadata": {
        "id": "gzwIRQMkAwuV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoK0guf5vbVN"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.9.0\n",
        "!pip install keras==2.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlpqS_Bz-PFw"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(101)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "#from keras import backend as K\n",
        "\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(101)\n",
        "from tensorflow.keras.applications.resnet import ResNet152, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import (BatchNormalization, Dense, Dropout, Flatten)\n",
        "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndz-tPFn_KPo"
      },
      "source": [
        "# **Create the directory structure**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7pMUCgRAKet"
      },
      "outputs": [],
      "source": [
        "# Create a new directory\n",
        "base_dir_1 = '/content/drive/MyDrive/.../base_dir_1'\n",
        "os.mkdir(base_dir_1)\n",
        "\n",
        "# [now we create 4 folder inside 'base_dir']\n",
        "# train_dir: av, ak, ez, ps\n",
        "# val_dir: av, ak, ez, ps\n",
        "\n",
        "# create a path to 'base_dir' to which I will join the names of the new folders\n",
        "# train_dir\n",
        "train_dir = os.path.join(base_dir_1, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# val_dir\n",
        "val_dir = os.path.join(base_dir_1,'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "# test_dir\n",
        "test_dir = os.path.join(base_dir_1, 'test_dir')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "# Create the new folders inside train_dir\n",
        "av = os.path.join(train_dir, 'av')\n",
        "os.mkdir(av)\n",
        "ak = os.path.join(train_dir, 'ak')\n",
        "os.mkdir(ak)\n",
        "ez = os.path.join(train_dir, 'ez')\n",
        "os.mkdir(ez)\n",
        "ps = os.path.join(train_dir, 'ps')\n",
        "os.mkdir(ps)\n",
        "\n",
        "# Create the new folders inside val_dir\n",
        "av = os.path.join(val_dir, 'av')\n",
        "os.mkdir(av)\n",
        "ak = os.path.join(val_dir, 'ak')\n",
        "os.mkdir(ak)\n",
        "ez = os.path.join(val_dir, 'ez')\n",
        "os.mkdir(ez)\n",
        "ps = os.path.join(val_dir, 'ps')\n",
        "os.mkdir(ps)\n",
        "\n",
        "# Create the new folders inside test_dir\n",
        "av = os.path.join(test_dir, 'av')\n",
        "os.mkdir(av)\n",
        "ak = os.path.join(test_dir, 'ak')\n",
        "os.mkdir(ak)\n",
        "ez = os.path.join(test_dir, 'ez')\n",
        "os.mkdir(ez)\n",
        "ps = os.path.join(test_dir, 'ps')\n",
        "os.mkdir(ps)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkvY6RdBBJ_2"
      },
      "source": [
        "Create a stratified train/test/val set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdZbKHMnBP6v"
      },
      "outputs": [],
      "source": [
        "df_data = pd.read_csv('/content/drive/MyDrive/Dataset/skin-lesion-dataset-new/Skin lesion full new_metadata.csv')\n",
        "\n",
        "df_data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGTg5HcWBV6a"
      },
      "outputs": [],
      "source": [
        "df_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa3O0EtMBooC"
      },
      "outputs": [],
      "source": [
        "y = df_data['dx']\n",
        "_, df_test = train_test_split(df_data, test_size = 0.15, random_state=101, stratify=y)\n",
        "df_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt44LsG-XMeH"
      },
      "outputs": [],
      "source": [
        "df_test['dx'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfMctHftHfps"
      },
      "source": [
        "Create a train set that excludes images that are in the val/test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMAcJyaYHsDA"
      },
      "outputs": [],
      "source": [
        "def identify_test_rows(x):\n",
        "  # create a list of all the lesion id in the val set\n",
        "  test_list = list(df_test['image_id'])\n",
        "\n",
        "\n",
        "  if str(x) in test_list:\n",
        "    return 'test'\n",
        "  else:\n",
        "    return 'train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-__0-U_JGSj"
      },
      "outputs": [],
      "source": [
        "df_data['train or test'] = df_data['image_id']\n",
        "df_data['train or test'] = df_data['train or test'].apply(identify_test_rows)\n",
        "\n",
        "df_train = df_data[df_data['train or test'] == 'train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2rCncBmKlAI"
      },
      "outputs": [],
      "source": [
        "print(len(df_train))\n",
        "print(len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhtpBxyXXz2b"
      },
      "outputs": [],
      "source": [
        "df_train.shape\n",
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChGgNeiLYowt"
      },
      "outputs": [],
      "source": [
        "del df_train['train or test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp7c1haeY9o1"
      },
      "outputs": [],
      "source": [
        "z = df_train['dx']\n",
        "_, df_val = train_test_split(df_train, test_size = 0.18, random_state=101, stratify=z)\n",
        "\n",
        "df_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwnivYblW65x"
      },
      "outputs": [],
      "source": [
        "def identify_val_rows(x):\n",
        "  # create a list of all the lesion id in the val set\n",
        "  val_list = list(df_val['image_id'])\n",
        "\n",
        "\n",
        "  if str(x) in val_list:\n",
        "    return 'val'\n",
        "  else:\n",
        "    return 'train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKFrncLUXeUZ"
      },
      "outputs": [],
      "source": [
        "df_train['train or val'] = df_train['image_id']\n",
        "df_train['train or val'] = df_train['train or val'].apply(identify_val_rows)\n",
        "\n",
        "df_train_1 = df_train[df_train['train or val'] == 'train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_TfeLvYYch0"
      },
      "outputs": [],
      "source": [
        "del df_train_1['train or val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGDRCmEqCygm"
      },
      "outputs": [],
      "source": [
        "df_val['dx'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRU_pLhzDOig"
      },
      "outputs": [],
      "source": [
        "df_train_1['dx'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCo-3xFYEF5t"
      },
      "outputs": [],
      "source": [
        "df_data['dx'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkzPj8FhaJEA"
      },
      "source": [
        "# **Transfer** the images into the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS_gYuQ0aUf6"
      },
      "outputs": [],
      "source": [
        "df_data.set_index('image_id', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDTrEWAGagJH"
      },
      "outputs": [],
      "source": [
        "folder = os.listdir('/content/drive/MyDrive/.../Skin-lesion-full-new')\n",
        "for file in folder:\n",
        "  print(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKWYtPwkaxo9"
      },
      "outputs": [],
      "source": [
        "# Get a list of train and val images\n",
        "train_list = list(df_train_1['image_id'])\n",
        "val_list = list(df_val['image_id'])\n",
        "test_list = list(df_test['image_id'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMKFwAKB6c9p"
      },
      "outputs": [],
      "source": [
        "print(train_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGvYMPu3wH03"
      },
      "outputs": [],
      "source": [
        "# Transfer the train images\n",
        "\n",
        "for image in train_list:\n",
        "  fname = image + '.jpg'\n",
        "  label = df_data.loc[image,'dx']\n",
        "\n",
        "  if fname in folder:\n",
        "    # source path to image\n",
        "    src = os.path.join('/content/drive/MyDrive.../Skin-lesion-full-new', fname)\n",
        "    # Destination path to image\n",
        "    dst = os.path.join('/content/drive/MyDrive/.../train_dir', label, fname)\n",
        "    # Copy the image from  source to de destination\n",
        "    shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUTk9JEjv_vg"
      },
      "outputs": [],
      "source": [
        "# Transfer the val images\n",
        "\n",
        "for image in val_list:\n",
        "  fname = image + '.jpg'\n",
        "  label = df_data.loc[image,'dx']\n",
        "\n",
        "  if fname in folder:\n",
        "    # source path to image\n",
        "    src = os.path.join('/content/drive/MyDrive/.../Skin-lesion-full-new', fname)\n",
        "    # Destination path to image\n",
        "    dst = os.path.join('/content/drive/MyDrive.../val_dir', label, fname)\n",
        "    # Copy the image from  source to de destination\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "# Transfer the test image\n",
        "\n",
        "for image in test_list:\n",
        "  fname = image + '.jpg'\n",
        "  label = df_data.loc[image,'dx']\n",
        "\n",
        "  if fname in folder:\n",
        "    # source path to image\n",
        "    src = os.path.join('/content/drive/MyDrive/.../Skin-lesion-full-new', fname)\n",
        "    # Destination path to image\n",
        "    dst = os.path.join('/content/drive/MyDrive/.../test_dir', label, fname)\n",
        "    # Copy the image from  source to de destination\n",
        "    shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohEq5uZvlEYn"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir('/content/drive/MyDrive/.../train_dir/ak')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/.../train_dir/av')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/.../train_dir/ez')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/.../train_dir/ps')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMd3jrJ9y_6Y"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir('/content/drive/MyDrive/.../val_dir/ak')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/.../val_dir/av')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/.../val_dir/ez')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/.../val_dir/ps')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqAs_MEXyt6d"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir('/content/drive/MyDrive/.../test_dir/ak')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/.../test_dir/av')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/.../test_dir/ez')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/.../test_dir/ps')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentation for **classes**"
      ],
      "metadata": {
        "id": "w0rWsQqjDAGP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq_SnhGFJZiM"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_list = ['ak', 'av', 'ez', 'ps']\n",
        "\n",
        "for item in class_list:\n",
        "\n",
        "    # We are creating temporary directories here because we delete these directories later\n",
        "    # create a base dir\n",
        "    aug_dir = '/content/drive/MyDrive/.../aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "    # create a dir within the base dir to store images of the same class\n",
        "    img_dir = os.path.join('/content/drive/.../aug_dir', 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        "\n",
        "    # Choose a class\n",
        "    img_class = item\n",
        "\n",
        "    # list all images in that directory\n",
        "    img_list = os.listdir('/content/drive/MyDrive/.../train_dir/' + img_class)\n",
        "\n",
        "    # Copy images from the class train dir to the img_dir e.g. class 'mel'\n",
        "    for fname in img_list:\n",
        "            # source path to image\n",
        "            src = os.path.join('/content/drive/MyDrive/.../train_dir/' + img_class, fname)\n",
        "            # destination path to image\n",
        "            dst = os.path.join('/content/drive/MyDrive/.../aug_dir/img_dir', fname)\n",
        "            # copy the image from the source to the destination\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "    # point to a dir containing the images and not to the images themselves\n",
        "    path = aug_dir\n",
        "    save_path = '/content/drive/MyDrive/.../base_dir_3/train_dir/' + img_class\n",
        "\n",
        "    # Create a data generator\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        #brightness_range=(0.9,1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    aug_datagen = datagen.flow_from_directory(path,\n",
        "                                           save_to_dir=save_path,\n",
        "                                           save_format='jpg',\n",
        "                                                    target_size=(224,224),\n",
        "                                                    batch_size=batch_size)\n",
        "\n",
        "\n",
        "\n",
        "    # Generate the augmented images and add them to the training folders\n",
        "\n",
        "    ###########\n",
        "\n",
        "    num_aug_images_wanted = 4000 # total number of images we want to have in each class\n",
        "\n",
        "    ###########\n",
        "\n",
        "    num_files = len(os.listdir('/content/drive/MyDrive/Dataset/skin-lesion-dataset-new/aug_dir/img_dir'))\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
        "\n",
        "    # run the generator and create about 4000 augmented images\n",
        "    for i in range(0,num_batches):\n",
        "\n",
        "        imgs, labels = next(aug_datagen)\n",
        "\n",
        "    # delete temporary directory with the raw image files\n",
        "    shutil.rmtree('/content/drive/MyDrive/Dataset/skin-lesion-dataset-new/aug_dir')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Some featured images after augmentation of datasets**"
      ],
      "metadata": {
        "id": "MEwm2ybJDb2z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucsrq9yy0MCU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# plots images with labels within jupyter notebook\n",
        "def plots(ims, figsize=(12,6), rows=5, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "plots(imgs, titles=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c0xwhvKU0oD"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir('/content/drive/MyDrive/Dataset/skin-lesion-dataset-new/base_dir_3/train_dir/ak')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/Dataset/skin-lesion-dataset-new/base_dir_3/val_dir/ak')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/Dataset/skin-lesion-dataset-new/base_dir_3/test_dir/ak')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7KdQStu0wIn"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/drive/MyDrive/Dataset/skin-lesion-dataset-new/base_dir_3/train_dir'\n",
        "valid_path = '/content/drive/MyDrive/Dataset/skin-lesion-dataset-new/base_dir_3/val_dir'\n",
        "test_path = '/content/drive/MyDrive/Dataset/skin-lesion-dataset-new/base_dir_3/test_dir'\n",
        "\n",
        "IMAGE_SHAPE = (192, 256, 3)\n",
        "data_gen_param = {\n",
        "    \"samplewise_center\": True,\n",
        "    \"samplewise_std_normalization\": True,\n",
        "    \"rotation_range\": 90,\n",
        "    \"width_shift_range\": 0.2,\n",
        "    \"height_shift_range\": 0.2,\n",
        "    \"zoom_range\": 0.2,\n",
        "    \"horizontal_flip\": True,\n",
        "    \"vertical_flip\": True,\n",
        "    \"rescale\": 1.0 / 255\n",
        "}\n",
        "data_generator = ImageDataGenerator(**data_gen_param)\n",
        "\n",
        "train_flow_param = {\n",
        "    \"directory\": train_path,\n",
        "    \"batch_size\": 64,\n",
        "    \"target_size\": IMAGE_SHAPE[:2],\n",
        "    \"shuffle\": True\n",
        "}\n",
        "train_flow = data_generator.flow_from_directory(**train_flow_param)\n",
        "\n",
        "val_flow_param = {\n",
        "    \"directory\": valid_path,\n",
        "    \"batch_size\": 64,\n",
        "    \"target_size\": IMAGE_SHAPE[:2],\n",
        "    \"shuffle\": False\n",
        "}\n",
        "val_flow = data_generator.flow_from_directory(**val_flow_param)\n",
        "\n",
        "test_flow_param = {\n",
        "    \"directory\": test_path,\n",
        "    \"batch_size\": 1,\n",
        "    \"target_size\": IMAGE_SHAPE[:2],\n",
        "    \"shuffle\": False\n",
        "}\n",
        "test_flow = data_generator.flow_from_directory(**test_flow_param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCr8i5qiMwAE",
        "outputId": "c3e4f1cf-3091-4f36-8e26-49af9726add8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.preprocessing.image.DirectoryIterator object at 0x7faf4c91f3a0>\n"
          ]
        }
      ],
      "source": [
        "print(test_flow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Teup4WpaQljM"
      },
      "source": [
        "### **Built the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsJKBnb2REtg"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import (BatchNormalization, Dense, Dropout, Flatten)\n",
        "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuLDMCVY0PaE"
      },
      "outputs": [],
      "source": [
        "pre_trained_model = ResNet152(input_shape= (192, 256, 3), include_top=False, weights = 'imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8tD81W_1WSY"
      },
      "outputs": [],
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "    print(layer.name)\n",
        "    layer.trainable = False\n",
        "\n",
        "print(len(pre_trained_model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09x9X7dq1Y0G"
      },
      "outputs": [],
      "source": [
        "last_layer = pre_trained_model.get_layer('conv5_block3_out')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rc9F-pM5Btr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMBxXxtx5DSu"
      },
      "outputs": [],
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(4, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z0nGwnURMli"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "def top_2_acc(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "def top_3_acc(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[categorical_accuracy, top_2_acc, top_3_acc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOIPGsPBSHr7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5thTxue7QwP"
      },
      "outputs": [],
      "source": [
        "for layer in pre_trained_model.layers[:75]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhrZaZTA7WDj"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[categorical_accuracy, top_2_acc, top_3_acc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8flVd8l7jB7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCOATnFUS5Lr"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/drive/MyDrive/.../ResNet152_28062023.h5\"\n",
        "\n",
        "checkpoint_param = {\n",
        "    \"filepath\": filepath,\n",
        "    \"monitor\": \"val_categorical_accuracy\",\n",
        "    \"verbose\": 1,\n",
        "    \"save_best_only\": True,\n",
        "    \"mode\": \"max\"\n",
        "}\n",
        "checkpoint = ModelCheckpoint(**checkpoint_param)\n",
        "\n",
        "lr_decay_params = {\n",
        "    \"monitor\": \"val_loss\",\n",
        "    \"factor\": 0.5,\n",
        "    \"patience\": 3,\n",
        "    \"min_lr\": 1e-5\n",
        "}\n",
        "lr_decay = ReduceLROnPlateau(**lr_decay_params)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSuF366RTMiV"
      },
      "outputs": [],
      "source": [
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 64\n",
        "val_batch_size = 64\n",
        "\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JhJ-RBOGTZQR"
      },
      "outputs": [],
      "source": [
        "fit_params = {\n",
        "    \"generator\": train_flow,\n",
        "    \"steps_per_epoch\": train_steps,\n",
        "    \"epochs\": 30,\n",
        "    \"verbose\": 1,\n",
        "    \"validation_data\": val_flow,\n",
        "    \"validation_steps\": val_steps,\n",
        "    \"callbacks\": [checkpoint, lr_decay, early_stopping]\n",
        "}\n",
        "print(\"Training the model...\")\n",
        "\n",
        "history = model.fit_generator(**fit_params)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion matrix**"
      ],
      "metadata": {
        "id": "B6-PWI2MLCwG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISfizOABSigf"
      },
      "outputs": [],
      "source": [
        "custom_object = {'top_2_acc':top_2_acc,\n",
        "                  'top_3_acc':top_3_acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI7L_P26l9Oz"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu_pKkNHr-do"
      },
      "outputs": [],
      "source": [
        "new_model_1 = tensorflow.keras.models.load_model('/content/drive/MyDrive/.../ResNet152.h5', custom_objects=custom_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXkGZHKTmE1b"
      },
      "outputs": [],
      "source": [
        "new_model_1.metrics_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JruiBbRBmRaW"
      },
      "outputs": [],
      "source": [
        "test_labels = test_flow.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R63HyVN2myzj"
      },
      "outputs": [],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaOlmkcHS9Di"
      },
      "outputs": [],
      "source": [
        "test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfCPKXqCsevc"
      },
      "outputs": [],
      "source": [
        "predictions = new_model_1.predict(test_flow, steps=len(df_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQAaN5gK1FlC"
      },
      "outputs": [],
      "source": [
        "classess = np.argmax(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaKIgcQzttAA"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17swTpCXty8l"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxBlvuQQt0Xm"
      },
      "outputs": [],
      "source": [
        "cm_plot_labels = ['ak', 'av', 'ez', 'ps']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7ozejojuAc8"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = test_flow.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqhEWH0BuBgu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_true, y_pred, target_names = cm_plot_labels)\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ROC-AUC**"
      ],
      "metadata": {
        "id": "FRZLKOB9LiO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "metadata": {
        "id": "KmmypYJtLmuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.array(y_test)\n",
        "n_classes = 4\n",
        "x_test = X_test.astype('float32')/255"
      ],
      "metadata": {
        "id": "LQD6MyAnLvwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_Y = new_model.predict(test_flow, steps=len(df_test), verbose=1)\n",
        "# Plot linewidth.\n",
        "lw = 2"
      ],
      "metadata": {
        "id": "EpHlOJKdL6qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred_Y[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), pred_Y.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ANqZHxEkL-j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GRAD-CAM**"
      ],
      "metadata": {
        "id": "DREMwjv_MG6q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inCMo8uBR68T"
      },
      "outputs": [],
      "source": [
        "label = ['ak', 'av', 'ez', 'ps']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTALqqt5SQ8E"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from collections.abc import  Sequence\n",
        "\n",
        "class _BaseWrapper(object):\n",
        "    \"\"\"\n",
        "    Please modify forward() and backward() according to your task.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        super(_BaseWrapper, self).__init__()\n",
        "        self.device = next(model.parameters()).device\n",
        "        self.model = model\n",
        "        self.handlers = []  # a set of hook function handlers\n",
        "\n",
        "    def _encode_one_hot(self, ids):\n",
        "        one_hot = torch.zeros_like(self.logits).to(self.device)\n",
        "        one_hot.scatter_(1, ids, 1.0)\n",
        "        return one_hot\n",
        "\n",
        "    def forward(self, image):\n",
        "        \"\"\"\n",
        "        Simple classification\n",
        "        \"\"\"\n",
        "        self.model.zero_grad()\n",
        "        self.logits = self.model(image)\n",
        "        self.probs = F.softmax(self.logits, dim=1)\n",
        "        return self.probs.sort(dim=1, descending=True)\n",
        "\n",
        "    def backward(self, ids):\n",
        "        \"\"\"\n",
        "        Class-specific backpropagation\n",
        "        Either way works:\n",
        "        1. self.logits.backward(gradient=one_hot, retain_graph=True)\n",
        "        2. (self.logits * one_hot).sum().backward(retain_graph=True)\n",
        "        \"\"\"\n",
        "\n",
        "        one_hot = self._encode_one_hot(ids)\n",
        "        self.logits.backward(gradient=one_hot, retain_graph=True)\n",
        "\n",
        "    def generate(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def remove_hook(self):\n",
        "        \"\"\"\n",
        "        Remove all the forward/backward hook functions\n",
        "        \"\"\"\n",
        "        for handle in self.handlers:\n",
        "            handle.remove()\n",
        "\n",
        "\n",
        "class GradCAM(_BaseWrapper):\n",
        "    \"\"\"\n",
        "    \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\"\n",
        "    https://arxiv.org/pdf/1610.02391.pdf\n",
        "    Look at Figure 2 on page 4\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, candidate_layers=None):\n",
        "        super(GradCAM, self).__init__(model)\n",
        "        self.fmap_pool = OrderedDict()\n",
        "        self.grad_pool = OrderedDict()\n",
        "        self.candidate_layers = candidate_layers  # list\n",
        "\n",
        "        def forward_hook(key):\n",
        "            def forward_hook_(module, input, output):\n",
        "                # Save featuremaps\n",
        "                self.fmap_pool[key] = output.detach()\n",
        "\n",
        "            return forward_hook_\n",
        "\n",
        "        def backward_hook(key):\n",
        "            def backward_hook_(module, grad_in, grad_out):\n",
        "                # Save the gradients correspond to the featuremaps\n",
        "                self.grad_pool[key] = grad_out[0].detach()\n",
        "\n",
        "            return backward_hook_\n",
        "\n",
        "        # If any candidates are not specified, the hook is registered to all the layers.\n",
        "        for name, module in self.model.named_modules():\n",
        "            if self.candidate_layers is None or name in self.candidate_layers:\n",
        "                self.handlers.append(module.register_forward_hook(forward_hook(name)))\n",
        "                self.handlers.append(module.register_backward_hook(backward_hook(name)))\n",
        "\n",
        "    def _find(self, pool, target_layer):\n",
        "        if target_layer in pool.keys():\n",
        "            return pool[target_layer]\n",
        "        else:\n",
        "            raise ValueError(\"Invalid layer name: {}\".format(target_layer))\n",
        "\n",
        "    def _compute_grad_weights(self, grads):\n",
        "        return F.adaptive_avg_pool2d(grads, 1)\n",
        "\n",
        "    def forward(self, image):\n",
        "        self.image_shape = image.shape[2:]\n",
        "        return super(GradCAM, self).forward(image)\n",
        "\n",
        "    def generate(self, target_layer):\n",
        "        fmaps = self._find(self.fmap_pool, target_layer)\n",
        "        grads = self._find(self.grad_pool, target_layer)\n",
        "        weights = self._compute_grad_weights(grads)\n",
        "\n",
        "        gcam = torch.mul(fmaps, weights).sum(dim=1, keepdim=True)\n",
        "        gcam = F.relu(gcam)\n",
        "\n",
        "        gcam = F.interpolate(\n",
        "            gcam, self.image_shape, mode=\"bilinear\", align_corners=False\n",
        "        )\n",
        "\n",
        "        B, C, H, W = gcam.shape\n",
        "        gcam = gcam.view(B, -1)\n",
        "        gcam -= gcam.min(dim=1, keepdim=True)[0]\n",
        "        gcam /= gcam.max(dim=1, keepdim=True)[0]\n",
        "        gcam = gcam.view(B, C, H, W)\n",
        "\n",
        "        return gcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHHI9fMITQL1"
      },
      "outputs": [],
      "source": [
        "def demo2(image, label, model):\n",
        "    \"\"\"\n",
        "    Generate Grad-CAM\n",
        "    \"\"\"\n",
        "    # Model\n",
        "    model = model\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # The layers\n",
        "    target_layers = [\"conv2\"]\n",
        "    target_class = label\n",
        "\n",
        "    # Images\n",
        "    images = image.unsqueeze(0)\n",
        "    gcam = GradCAM(model=model)\n",
        "    probs, ids = gcam.forward(images)\n",
        "    ids_ = torch.LongTensor([[target_class]] * len(images)).to(device)\n",
        "    gcam.backward(ids=ids_)\n",
        "\n",
        "    for target_layer in target_layers:\n",
        "        print(\"Generating Grad-CAM @{}\".format(target_layer))\n",
        "\n",
        "        # Grad-CAM\n",
        "        regions = gcam.generate(target_layer=target_layer)\n",
        "        for j in range(len(images)):\n",
        "            print(\n",
        "                \"\\t#{}: {} ({:.5f})\".format(\n",
        "                    j, classes[target_class], float(probs[ids == target_class])\n",
        "                )\n",
        "            )\n",
        "\n",
        "            gcam=regions[j, 0]\n",
        "            plt.imshow(gcam.cpu())\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FdwuSepTi7l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1gSmi3K4QnvO2CCYxT57RcHJM6sLt6ATY",
      "authorship_tag": "ABX9TyNoH/zOsPPxStmM5i4A0yVn",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}